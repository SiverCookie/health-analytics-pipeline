ğŸ“Œ Health Analytics ETL Pipeline
![Python](https://img.shields.io/badge/Python-3.11-blue)
![Platform](https://img.shields.io/badge/Platform-Windows%2010%2F11-lightgrey)
![Docker](https://img.shields.io/badge/Docker-Ready-brightgreen)
![Prefect](https://img.shields.io/badge/Orchestration-Prefect%203-blueviolet)
![CI/CD](https://img.shields.io/badge/GitHub_Actions-CI%2FCD-success)
![Tests](https://img.shields.io/badge/Tests-Pytest-green)
![Status](https://img.shields.io/badge/Build-Passing-brightgreen)

A Python-based data engineering pipeline for cleaning, validating, and loading simulated wearable device data.

ğŸ§© Overview

This project implements a complete ETL pipeline for processing synthetic health data (heart rate & step count) typically collected from wearable devices.

The pipeline includes:

Data Extraction (CSV-based raw ingestion)

Data Cleaning & Validation (timestamp parsing, numeric checks, anomaly filtering)

Data Quality Reporting (before & after cleaning)

ETL Orchestration with Prefect

Automated Tests (pytest)

CI/CD (GitHub Actions)

Dockerized execution for reproducibility

ğŸ’¡ All development and testing were performed on Windows 10/11.
The project runs fully on Windows, both locally and inside Docker Desktop.

ğŸ— Project Architecture

health-analytics-pipeline/
â”‚
â”œâ”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py              # Load raw CSV data
â”‚   â”œâ”€â”€ transform.py            # Clean heart_rate and steps
â”‚   â”œâ”€â”€ quality_checks.py       # Validation rules + quality scoring
â”‚   â”œâ”€â”€ load.py                 # Load cleaned data into SQLite
â”‚   â”œâ”€â”€ pipeline.py             # Prefect 3 orchestration flow
â”‚   â”œâ”€â”€ run_local_no_prefect.py # Standalone ETL execution (used in Docker)
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tests/                      # pytest test suite
â”‚
â”œâ”€â”€ raw_data/                   # Sample .csv data
â”‚
â”œâ”€â”€ db/                         # SQLite database (generated)
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md

ğŸ–¼ ETL Flow Diagram

        +-----------------+
        |     Extract     |
        | (CSV â†’ DataFrame)
        +--------+--------+
                 |
                 v
        +-----------------+
        | Raw Quality     |
        | Checks          |
        +--------+--------+
                 |
                 v
        +-----------------+
        |   Transform     |
        | (Cleaning & Fix)|
        +--------+--------+
                 |
                 v
        +-----------------+
        | Clean Quality   |
        | Checks          |
        +--------+--------+
                 |
                 v
        +-----------------+
        |      Load       |
        |   (SQLite)      |
        +-----------------+

ğŸš€ Features
âœ” 1. Realistic ETL Logic

timestamp corrections

invalid numeric filtering

heart rate physiological range checks

negative/invalid step counts

duplicate row detection

âœ” 2. Automated Data Quality Reports

Before cleaning â†’ After cleaning
Saved as:

quality_raw.json
quality_clean.json

âœ” 3. SQLite Loading

Tables created automatically:

heart_rate

steps

âœ” 4. Dockerized Execution

Completely reproducible ETL run using:

docker build -t health-etl .
docker run --rm health-etl

âœ” 5. Windows-first development

Everything runs natively on Windows:

Python

Prefect

Docker Desktop

SQLite

pytest

âœ” 6. CI/CD Pipeline

GitHub Actions automatically runs:

install deps

run test suite

report results

ğŸ§ª Running the ETL Pipeline Locally (Windows)
1ï¸âƒ£ Create virtual environment
python -m venv venv
venv\Scripts\activate

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Run the ETL using Prefect (full orchestration)
python etl/pipeline.py

4ï¸âƒ£ Run unit tests
pytest

ğŸ³ Running the ETL in Docker (Recommended)
1ï¸âƒ£ Build the image
docker build -t health-etl .

2ï¸âƒ£ Run the ETL
docker run --rm health-etl


Inside Docker, the ETL is executed via:

etl/run_local_no_prefect.py


This script runs without Prefectâ€™s orchestration engine, ensuring stable execution inside containers.

ğŸ—„ Database Output

After running the pipeline (local or Docker):

db/
â””â”€â”€ health.db


Tables:

heart_rate

steps

You can inspect the database using tools like DB Browser for SQLite.

ğŸ¯ Why This Project Matters (Recruiter-Friendly Summary)

This project demonstrates:

ğŸ”¹ Real-world ETL engineering skills

Handling messy health data and implementing cleaning & validation steps.

ğŸ”¹ Knowledge of modern orchestration tools

Prefect 3 used for workflow orchestration.

ğŸ”¹ CI/CD exposure

GitHub Actions pipeline for automated testing.

ğŸ”¹ Software engineering best practices

Modular code, testing, version control, and documentation.

ğŸ”¹ Docker proficiency

Containerized ETL pipeline suitable for production-like workflows.

ğŸ”¹ Python proficiency

Pandas, NumPy, data validation, file handling, SQLite integration.

ğŸ“¬ Contact

Vlad-Petru OpriÈ™
(www.linkedin.com/in/vlad-opris-194171196)

ğŸ Final Notes

This project was:

developed entirely on Windows

tested on Windows + Docker Desktop (Linux containers)

validated via automated CI/CD

It is designed as a portfolio-grade example of Python-based automation, ETL engineering, and modern workflow orchestration.